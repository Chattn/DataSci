# -*- coding: utf-8 -*-
"""Finale_pj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cvA0aKSp15vEfQD9-hNku99MnqVMPkqe

# Final Project Challenge
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt
import seaborn as sns
import statistics

plt.rc('figure', figsize=(10, 8))
np.set_printoptions(precision=4, suppress=True)

"""### Input Data

อ่านไฟล์ train และ test
"""

train_dt = pd.read_csv('train_file.csv') 
test_dt = pd.read_csv('test_file.csv')

train_dt.head()

test_dt.head()

"""### Data Infomation

ดูข้อมูลทั่วๆไปของ train และ test data
"""

train_dt.info() #ดูข้อมูลทั้งหมดข้อตาราง train

train_dt.shape #ดูขนาดข้อมูลทั้งหมด

test_dt.info() #ดูข้อมูลทั้งหมดข้อตาราง test

test_dt.shape #ดูขนาดข้อมูลทั้งหมด

"""### Data Transformation"""

test_dt.isnull().any() #หาว่ามีข้อมูลตรงไหนบ้างที่ null

train_dt.isnull().any() #หาว่ามีข้อมูลตรงไหนบ้างที่ null

"""พบว่าเจอค่า null ทั้งหมด 7 ที่ได้แก่ 
- Gender
- Married
- Dependents
- Self_Employed
- LoanAmount
- Loan_Amount_Term
- Credit_History
"""

train_dt.isnull().sum() #ดูว่ามี null กี่ row

pcc = (train_dt.isnull().sum() / train_dt.isnull().count() * 100)
result  = pcc.sum()
print("null =" , result , "%")

"""ข้อมูล null คิดเป็น 24.26% จากข้อมูลทั้งหมด ดังนั้นเราไม่ควรลบ

"""

train_dt.shape #ดูขนาดข้อมูลทั้งหมด

train_dt.duplicated().any() #ดูว่ามีข้อมูลซ้ำกันหรือไม่

#แปลงค่าข้อมูลบางส่วน
##### Train ######
train_dt['Gender'] = train_dt['Gender'].fillna("Unknown") 
train_dt['Married'] = train_dt['Married'].fillna("No") 
train_dt['Self_Employed'] = train_dt['Self_Employed'].fillna("Unknown") 
##### Test ######
test_dt['Gender'] = test_dt['Gender'].fillna("Unknown") 
test_dt['Self_Employed'] = test_dt['Self_Employed'].fillna("Unknown")

"""ดูค่าว่า เมื่อเราเปลี่ยนค่าใน column แล้วค่าข้างในจะเป็นอย่างไร"""

train_dt['Gender'].unique()

test_dt['Gender'].unique()

"""เช็คว่าค่าใน train และ test มีค่า Null อยู่หรือไม่"""

train_dt.isnull().any()

test_dt.isnull().any()

#ทำการเติมข้อมูลที่ขาดหายไปของ Train
train_dt['LoanAmount'] = train_dt['LoanAmount'].fillna(train_dt['LoanAmount'].mean()) #เราจะเติม null ของ loan amount โดยใช้ค่าเฉลี่ย 
train_dt['Credit_History'] = train_dt['Credit_History'].fillna(train_dt['Credit_History'].mean()) #เราจะเติม null ของ Credit_History โดยใช้ค่าเฉลี่ย 
train_dt['Loan_Amount_Term'] = train_dt['Loan_Amount_Term'].fillna(train_dt['Loan_Amount_Term'].mean()) #เราจะเติม null ของ Loan_Amount_Term โดยใช้ค่าเฉลี่ย 

#ทำการเติมข้อมูลที่ขาดหายไปของ Test
test_dt['LoanAmount'] = test_dt['LoanAmount'].fillna(test_dt['LoanAmount'].mean()) #เราจะเติม null ของ loan amount โดยใช้ค่าเฉลี่ย 
test_dt['Credit_History'] = test_dt['Credit_History'].fillna(test_dt['Credit_History'].mean()) #เราจะเติม null ของ Credit_History โดยใช้ค่าเฉลี่ย 
test_dt['Loan_Amount_Term'] = test_dt['Loan_Amount_Term'].fillna(test_dt['Loan_Amount_Term'].mean()) #เราจะเติม null ของ Loan_Amount_Term โดยใช้ค่าเฉลี่ย

#ทำการเปลี่ยนค่าของ Dependents จากค่า string ให้เป็น int
#เราจะให้ 0 คือ 0 คน
#เราจะให้ 1 คือ 1 คน
#เราจะให้ 2 คือ 2 คน
#เราจะให้ 3 คือ 3 คนขึ้นไป(แทน 3+ อันเก่า)

#train
train_dt['Dependents'] = train_dt['Dependents'].fillna("0") 
train_dt['Dependents'][train_dt['Dependents'] == "3+"] = "3"
train_dt['Dependents'] = train_dt['Dependents'].astype('int64')

#test
test_dt['Dependents'] = test_dt['Dependents'].fillna("0") 
test_dt['Dependents'][test_dt['Dependents'] == "3+"] = "3"
test_dt['Dependents'] = test_dt['Dependents'].astype('int64')

"""columns Dependents เป็น datatype int 64 """

train_dt['Dependents'].unique()

test_dt['Dependents'].unique()

train_dt['Dependents'].dtypes

test_dt['Dependents'].dtypes

"""ต้องการดูทั้ง train และ test ว่ายังมี null อยู่หรือป่าว"""

train_dt.isnull().any()

test_dt.isnull().any()

"""### Data Visualization EDA"""

train_dt.describe() #ความสัมพันธ์ของตาราง train

"""- ผู้กู้ส่วนใหญ่ 50% มักจะกู้เพียงตัวคนเดียว และ 75% จะมีผู้ร่วมกู้ 1 คน 
- จะพบว่าโดยเฉลี่ยแล้วรายได้ของผู้กู้ยืม(ApplicantIncome) คือ 5403 ซึ่ง 50% ของผู้กู้ยืม มีรายได้ 3812 และรายได้ของผู้กู้ยืมต่ำที่สุด คือ 150 และสูงที่สุด คือ 81000
- จะพบว่าผู้กู้ยืมร่วมโดยเฉลี่ยแล้วรายได้ของผู้กู้ยืมร่วม(CoaaplicantIncome) คือ 1621 ซึ่ง 50% ของผู้กู้ยืมร่วม มีรายได้ 1188 และรายได้ของผู้กู้ยืมร่วมที่ต่ำที่สุด คือ 0 และสูงที่สุด คือ 41667
- จะพบว่าโดยเฉลี่ยแล้วจำนวนเงินกู้(LoanAmount) คือ 146 ซึ่ง 50% ของผู้กู้ยืมมีจำนวนเงินกู้เท่ากับ 129 ซึ่งจำนวนเงินกู้ที่ต่ำที่สุด คือ 9 และสูงที่สุด คือ 700
- จะพบว่าระยะเวลาของการกู้เงินโดยเฉลี่ย คือ 342 วัน และมีจำนวนวันที่กู้ต่ำที่สุด คือ 12 วัน และสูงสุด 480 วัน ซึ่ง 50% จะมีระยะเวลาการกู้ 360 วัน
- จะพบว่าผู้ที่กู้ส่วนใหญ่(เกิน75%)มีเครดิตการกู้ที่ดี
"""

train_dt.describe(include="object") #ดูค่าทางสถิติต่างๆของข้อมูลที่เป็น object

"""- พบว่าผู้กู้ส่วนใหญ่เป็นเพศชายซึ่งคิดเป็นจำนวน 489 คน จาก 614 คน
- ผู้กู้ส่วนใหญ่แต่งงานแล้ว คิดเป็นจำนวน 398 คน จาก 614 คน
- ผู้กู้ส่วนใหญ่ซึ่งเป็นจำนวน 480 คน จาก 614 คน จบการศึกษาแล้ว
- ผู้กู้ส่วนใหญ่มีอาชีพเป็นหลักแหล่ง ไม่ทำอาชีพอิสระ ซึ่งมีจำนวนมากถึง 500 จาก 614 คน
- ผู้กู้ส่วนใหญ่มักมีทรัพย์สมบัติ คือ พื้นที่หรือบ้านในที่กึ่งเมืองกึ่งชุมชน

กราฟแสดงความสัมพันธ์ระหว่าง Education และ Loan Status
"""

sns.countplot(x='Education',hue='Loan_Status',data=train_dt)

"""กราฟแสดงความสัมพันธ์ระหว่าง Married และ Loan Status



"""

sns.countplot(x='Married',hue='Loan_Status',data=train_dt)

"""กราฟแสดงความสัมพันธ์ระหว่าง 5 columns : Dependents, ApplicantIncome, CoapplicantIncome,LoanAmount, Loan Amount Term และ Credit_History"""

fig,ax = plt.subplots(figsize=(10,10))
sns.heatmap(train_dt.corr(),ax=ax,annot= True,linewidth= 0.02,fmt='.2f',cmap = 'Blues')
plt.show()

"""### Preprocessing"""

from sklearn.impute import SimpleImputer

train_dt.dtypes

from sklearn.preprocessing import scale, StandardScaler, MinMaxScaler, OneHotEncoder
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder

status = ['Y','N']  #ทำการกำหนดว่า status จะมีค่าเป็น Y และ N

ordi = OrdinalEncoder(categories=[status])

ordi.fit(train_dt[['Loan_Status']])

ordi.transform(train_dt[['Loan_Status']]) #ดูผลลัพธ์จากการกำหนดค่า โดย Y เป็น 0 และ N เป็น 1

train_dt[['Gender','Married','Education','Self_Employed','Property_Area']].head() #ต้องการรู้ว่าcolumnsไหนยังไม่เป็นตัวเลข

#ทำ onehot encoder เพื่อเปลี่ยน column ที่ต้องการให้เป็นตัวเลข
onehot =  make_pipeline(OneHotEncoder())
preprocessing = ColumnTransformer(
    [('5type', onehot, ['Gender','Married','Education','Self_Employed','Property_Area']),], remainder='passthrough')

#set ค่า X_pred ไว้ทำ model X_test ไปทำการ testing
X_pred = preprocessing.fit_transform(train_dt)
X_test = preprocessing.fit_transform(test_dt)

x_pred_dt=pd.DataFrame(X_pred)
x_pred_dt.head()

X_test_dt = pd.DataFrame(X_test)
X_test_dt.head()

#drop columns ที่ไม่ต้องการใช้
x_pred_dt = x_pred_dt.drop(13,1)
x_pred_dt = x_pred_dt.drop(20,1)
X_test_dt = X_test_dt.drop(13,1)

x_pred_dt.shape
X_test_dt.shape

"""### Model

Model ที่กลุ่มเราเลือกคือ RandomForest, Tree และ AdaBoostClassifier หลังจากนั้นเอามา ensemble โดยใช้ Voting Classifier แบบ hard ในการตัดสินใจ
"""

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier

#นำค่าที่ต้องการมาใส่ใน x y และ split เป็น train และ test set
x = x_pred_dt 
y = train_dt['Loan_Status']

X_train, X_test, y_train, y_test = train_test_split(x,y)

"""Declare classifier"""

forest = RandomForestClassifier(n_estimators = 1000, criterion='entropy', oob_score=True, random_state=None,n_jobs=-1)
tree = DecisionTreeClassifier(criterion='entropy',max_depth=2)
ada = AdaBoostClassifier(base_estimator=tree, n_estimators=500, learning_rate=0.2, random_state=0)

"""Model building using ensemble"""

from sklearn.ensemble import VotingClassifier
model_predict =  VotingClassifier(estimators = [('forest',forest),('tree',tree),('adaboost', ada)], voting ='hard')
model_predict.fit(X_train, y_train)

model_predict.score(X_test,y_test) #บอก model accuracy จากการใช้ test set prediction

"""เอา test ที่ต้องการส่ง Submission ส่งเข้า list ก่อนนำเข้าไฟล์ csv """

result =[]
for i in range(X_test_dt.shape[0]):
  result.append(model_predict.predict(X_test_dt.loc[[i]])[0])

"""### Submission file

หลังจากเอา test set เข้า list แล้วนำ list นั้นไปเข้า file csv เพื่อส่งขึ้น - https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/
"""

submit = pd.DataFrame(columns=['Loan_ID','Loan_Status']) #เอาแค่ colmuns Loan_ID และ Loan_Status

submit['Loan_ID'] = test_dt['Loan_ID']

submit['Loan_Status']= result

submit.head()

submit.to_csv('submission_file.csv',index=False)